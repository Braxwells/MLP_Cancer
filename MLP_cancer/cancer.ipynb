{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras as ks\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos el archivo csv a nuestro programa para más adelante dividirlo y asi poder entrenar nuestra ia\n",
    "cancer_df = pd.read_csv(r'C:\\Users\\Bru\\Desktop\\Uni\\Trabajos\\Chia\\MLP_cancer\\cancer_dataset.csv')\n",
    "\n",
    "#Como vemos que hay una columna nula (por un error), la borramos para evitar fallos más adelante\n",
    "cancer_df = cancer_df.drop('Unnamed: 32',axis=1)\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dividimos nuestro csv en x e y pues estos serán una primera división para poder entrenar nuestra ia\n",
    "x = cancer_df.iloc[:,2:].values\n",
    "y = cancer_df.iloc[:,1].values\n",
    "\n",
    "#Codificamos las 'm' y 'b' por 1 y 0. Lo hacemos ya que no entendería los datos con letras\n",
    "labelencoder_Y = LabelEncoder()\n",
    "labelencoder_Y.fit(y)\n",
    "y2 = labelencoder_Y.transform(y)\n",
    "\n",
    "#Utilizamos keras to_categorical para así poder categorizar los datos y convertir la variable en una matriz de variables binarias\n",
    "y3 = to_categorical(y2)\n",
    "y = np.argmax(y3, axis=1)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.029e+00, 1.733e+01, 5.879e+01, ..., 1.750e-01, 4.228e-01,\n",
       "        1.175e-01],\n",
       "       [2.109e+01, 2.657e+01, 1.427e+02, ..., 2.903e-01, 4.098e-01,\n",
       "        1.284e-01],\n",
       "       [9.173e+00, 1.386e+01, 5.920e+01, ..., 5.087e-02, 3.282e-01,\n",
       "        8.490e-02],\n",
       "       ...,\n",
       "       [1.429e+01, 1.682e+01, 9.030e+01, ..., 3.333e-02, 2.458e-01,\n",
       "        6.120e-02],\n",
       "       [1.398e+01, 1.962e+01, 9.112e+01, ..., 1.827e-01, 3.179e-01,\n",
       "        1.055e-01],\n",
       "       [1.218e+01, 2.052e+01, 7.722e+01, ..., 7.431e-02, 2.694e-01,\n",
       "        6.878e-02]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Una vez dividimos los datos según su función, los volvemos a dividir en 2 grupos para separar los datos de entrenamiento a los de test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalizamos los datos para que así puedan ser comparables de una forma más eficaz y que se obtenga un rendimiento mucho mejor y estable\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ahora que ya tenemos todos los datos preparados para ser implementados, creamos la red neuronal.\n",
    "#En este caso al estar obligados a usar un optimizador y funciones de activación y error concretas nos quedamos algo 'limitados'\n",
    "#Aún así usamos dos funciones relu con 16 neuronas cada una y una sigmoide con 32 neuronas. \n",
    "#Además de eso añadimos otra sigmoide final la cual tiene una única neurona pues esta nos indicará la salida (0,1)\n",
    "model = ks.models.Sequential()\n",
    "\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(32, activation= 'sigmoid'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9956\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9956\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9956\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9956\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9956\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9956\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9956\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9956\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9956\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9956\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9978\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9978\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9978\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9978\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9978\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9978\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9978\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.9978\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9978\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9978\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9978\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9978\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9978\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9978\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9978\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9978\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9978\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9978\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9978\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9978\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9978\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9978\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.9978\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9978\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9978\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.9978\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9978\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9978\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9978\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9978\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9978\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9978\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9978\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9978\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9978\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9978\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9978\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9978\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9978\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9978\n"
     ]
    }
   ],
   "source": [
    "#Ahora que ya tenemos la estructura de nuestra IA, comenzamos a entrenarla\n",
    "#Para ello creamos un total de 50 épocas (ciclos por los que toda la información que le dimos al principio pasa por la red).\n",
    "#Tambien usamos un batch size de 33 (número de datos que tendrá cada época realizada)\n",
    "#Ambas variables fueron elegidas tras diferentes pruebas hasta que logramos una buena precisión\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0222 - accuracy: 0.9737 - 42ms/epoch - 10ms/step\n",
      "Precisión del modelo en los datos de prueba: 0.9736841917037964\n"
     ]
    }
   ],
   "source": [
    "#Ahora que tenemos la IA entrenada queremos ver como de bien fue el entrenamiento\n",
    "#Para eso utilizamos el codigo de abajo el cual nos devolvera datos interesantes como su precisión o el tiempo que ha tardado en realizar una época (los datos son calculados con la media)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Precisión del modelo en los datos de prueba:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "['Benigno', 'Maligno', 'Maligno', 'Benigno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Maligno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Maligno', 'Maligno', 'Maligno', 'Maligno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Maligno', 'Maligno', 'Benigno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Maligno', 'Benigno', 'Benigno', 'Maligno']\n"
     ]
    }
   ],
   "source": [
    "#Como ya tenemos creada la IA y totalmente funcional, ahora es momento de probarla. \n",
    "#Para ello creamos una función que cambia los valores 1 y 0 en maligno o benigno para una mejor comprensión\n",
    "def cambio_etiqueta(etiqueta_binaria):\n",
    "    if etiqueta_binaria == 0:\n",
    "        return \"Benigno\"\n",
    "    else:\n",
    "        return \"Maligno\"\n",
    "\n",
    "\n",
    "#Finalmente usamos los datos que habíamos reservado al principio del proyecto para los test.\n",
    "#Para ello usamos un umbral del 99% para minimizar errores y luego el código que ejecuta nuestra IA.\n",
    "#Además implementamos la función de cambio de etiquetas anterior para asi poder entender los datos de una forma mas cómoda\n",
    "prob = model.predict(x_test)\n",
    "umbral = 0.99\n",
    "predicciones = (prob > umbral).astype(int)\n",
    "predicciones_clase = [cambio_etiqueta(etiqueta_binaria) for etiqueta_binaria in predicciones]\n",
    "print(predicciones_clase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
